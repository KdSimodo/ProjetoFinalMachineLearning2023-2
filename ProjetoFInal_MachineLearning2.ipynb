{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:30px;\">Projeto Final Machine Learning - Tutorial de indentificação de imagens</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:25px;\">Introdução</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O reconhecimento de imagem é uma área da inteligência artificial que permite que computadores \"vejam\" e interpretem o conteúdo visual de imagens. Uma aplicação prática disso é o reconhecimento de objetos em imagens, identificação de rostos, entre muitos outros cenários. Neste tutorial, vamos explorar como realizar reconhecimento de imagem em Python, utilizando a biblioteca Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:25px;\">Introdução às bibliotecas</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como dito anteriormente, nesse tutorial utilizaremos a biblioteca Pytorch, uma biblioteca de aprendizado de máquina de código aberto para Python, desenvolvida principalmente pelo Facebook's AI Research lab (FAIR). Ele é usado para desenvolver aplicativos de aprendizado de máquina e deep learning.  Para utilizar a biblioteca, é primeiramente necessário importá-la, assim como outras bibliotecas que serão utilizadas nesse tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:25px;\">Problema Exemplo</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar o entendimento, vamos considerar a seguinte situação como um exemplo. Suponha que um fazendeiro quer descobrir se suas plantas estão doentes. Como a identificação das doenças pode ser difícil se realizada a olho nu, ele decidiu implementar um modelo que recebe imagens das plantas e as classificas como saudáveis ou doentes. O conjunto de imagens utilizado para esse exemplo foi obtido no Kaggle, segundo o link https://www.kaggle.com/datasets/csafrit2/plant-leaves-for-image-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:25px;\">Preparação de Dados</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro passo na montagem do modelo é o carregamento dos dados. Normalmente o conjunto de dados deveria ser dividido em conjuntos de teste e treino. Entretanto, como os dados citados acima já vem separados, usaremos os dados já separados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caminho para o diretório do conjunto de treino\n",
    "diretorio_treino = 'Plants_2/train'\n",
    "#Caminho para o diretório do conjunto de teste\n",
    "diretorio_teste = 'Plants_2/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o pytorch trabalha com tensores, a estrutura de dados básica usada por esses frameworks para representar dados, é necessário converter as imagens para tensores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "largura = 250\n",
    "altura = 250\n",
    "\n",
    "#esse transformador ira alterar o tamanho das imagens e então convertelas para tensores\n",
    "transformador = transforms.Compose([\n",
    "    transforms.Resize((largura, altura)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Transformação do dataset e leitura de dados\n",
    "dataset_treino = ImageFolder(root=diretorio_treino, transform=transformador)\n",
    "dataset_teste = ImageFolder(root=diretorio_teste, transform=transformador)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa aplicação estamos mudando a largura e a altura das imagens, para economizar memoria (uma vez que as fotos já vêm na mesma dimensão), e normalizando. Foi aplicada uma normalização pois foi utilizado um modelo já treinado para a classificação. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a leitura de dados, foi utilizado o comando ImageFolder, uma função do pytorch que facilita o carregamento de  conjuntos de dados de imagens quando os dados seguem uma estrutura específica de pastas. Como no dataset utilizado cada subpasta contém imagens de uma classe específica, essa função pode ser utilizada na leitura dos dados. Ele também atribui classes automaticamente segundo as pastas. Podemos verificar as classes com o comando abaixo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alstonia Scholaris diseased (P2a)', 'Alstonia Scholaris healthy (P2b)', 'Arjun diseased (P1a)', 'Arjun healthy (P1b)', 'Bael diseased (P4b)', 'Basil healthy (P8)', 'Chinar diseased (P11b)', 'Chinar healthy (P11a)', 'Gauva diseased (P3b)', 'Gauva healthy (P3a)', 'Jamun diseased (P5b)', 'Jamun healthy (P5a)', 'Jatropha diseased (P6b)', 'Jatropha healthy (P6a)', 'Lemon diseased (P10b)', 'Lemon healthy (P10a)', 'Mango diseased (P0b)', 'Mango healthy (P0a)', 'Pomegranate diseased (P9b)', 'Pomegranate healthy (P9a)', 'Pongamia Pinnata diseased (P7b)', 'Pongamia Pinnata healthy (P7a)']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.6392, -0.6314, -0.6235,  ..., -0.7020, -0.7098, -0.7176],\n",
       "          [-0.6157, -0.6157, -0.6078,  ..., -0.7098, -0.7098, -0.7098],\n",
       "          [-0.6235, -0.6157, -0.6078,  ..., -0.7020, -0.7020, -0.7020],\n",
       "          ...,\n",
       "          [-0.7804, -0.7725, -0.7725,  ..., -0.8118, -0.8118, -0.8118],\n",
       "          [-0.7804, -0.7725, -0.7647,  ..., -0.8196, -0.8196, -0.8118],\n",
       "          [-0.7725, -0.7647, -0.7569,  ..., -0.8196, -0.8196, -0.8196]],\n",
       " \n",
       "         [[-0.5608, -0.5529, -0.5451,  ..., -0.6000, -0.6078, -0.6157],\n",
       "          [-0.5373, -0.5373, -0.5294,  ..., -0.6078, -0.6078, -0.6078],\n",
       "          [-0.5451, -0.5373, -0.5294,  ..., -0.6000, -0.6078, -0.6078],\n",
       "          ...,\n",
       "          [-0.7804, -0.7725, -0.7725,  ..., -0.8118, -0.8118, -0.8196],\n",
       "          [-0.7804, -0.7725, -0.7647,  ..., -0.8196, -0.8118, -0.8196],\n",
       "          [-0.7725, -0.7647, -0.7647,  ..., -0.8275, -0.8275, -0.8275]],\n",
       " \n",
       "         [[-0.4824, -0.4745, -0.4667,  ..., -0.4667, -0.4745, -0.4824],\n",
       "          [-0.4588, -0.4588, -0.4510,  ..., -0.4745, -0.4745, -0.4745],\n",
       "          [-0.4667, -0.4667, -0.4588,  ..., -0.4745, -0.4745, -0.4667],\n",
       "          ...,\n",
       "          [-0.7647, -0.7569, -0.7569,  ..., -0.7804, -0.7725, -0.7804],\n",
       "          [-0.7647, -0.7569, -0.7490,  ..., -0.7804, -0.7804, -0.7804],\n",
       "          [-0.7569, -0.7490, -0.7412,  ..., -0.7882, -0.7882, -0.7882]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset_treino.classes)\n",
    "dataset_treino[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para simplificar a análise, vamos agrupar as diferentes plantas em grupos de saldáveis ou doentes. Essas são as classes que serão agrupadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Selecionar classes para serem agrupadas\n",
    "doentes = ['Alstonia Scholaris diseased (P2a)', 'Arjun diseased (P1a)', 'Bael diseased (P4b)',\n",
    "           'Chinar diseased (P11b)', 'Gauva diseased (P3b)', 'Jamun diseased (P5b)', 'Jatropha diseased (P6b)',\n",
    "           'Lemon diseased (P10b)', 'Mango diseased (P0b)', 'Pomegranate diseased (P9b)',\n",
    "           'Pongamia Pinnata diseased (P7b)']\n",
    "\n",
    "saudaveis = ['Alstonia Scholaris healthy (P2b)', 'Arjun healthy (P1b)', 'Basil healthy (P8)', 'Chinar healthy (P11a)',\n",
    "              'Gauva healthy (P3a)', 'Jamun healthy (P5a)', 'Jatropha healthy (P6a)', 'Lemon healthy (P10a)', 'Mango healthy (P0a)',\n",
    "                'Pomegranate healthy (P9a)', 'Pongamia Pinnata healthy (P7a)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupando as classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treino Doentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número de amostras na classe \"Doentes\" é: 2111\n"
     ]
    }
   ],
   "source": [
    "#Para evitar acidentes, vou clonar o conjunto de treino e teste\n",
    "treino = dataset_treino\n",
    "\n",
    "#nome da nova classe\n",
    "nova_classe_doentes = 'Doentes'\n",
    "\n",
    "df = pd.DataFrame(treino.imgs, columns=['caminho', 'rotulo'])\n",
    "\n",
    "#verifica se classe ja esta no dataset\n",
    "if nova_classe_doentes not in treino.classes:\n",
    "    treino.classes.append(nova_classe_doentes)\n",
    "\n",
    "nova_classe_idx = len(treino.classes)\n",
    "\n",
    "\n",
    "novas_amostras = []\n",
    "\n",
    "# Itera pelas classes na lista e adiciona os elementos à lista criada anteriormente\n",
    "for caminho, rotulo in treino.imgs:\n",
    "    nome_classe = treino.classes[rotulo]\n",
    "    novo_rotulo = nova_classe_idx if nome_classe in doentes else rotulo\n",
    "    novas_amostras.append((caminho, novo_rotulo))\n",
    "\n",
    "# Atualiza as amostras no conjunto de treino\n",
    "treino.imgs = novas_amostras\n",
    "\n",
    "# Atualiza o DataFrame\n",
    "df['rotulo'] = [rotulo for (_, rotulo) in treino.imgs]\n",
    "\n",
    "\n",
    "numero_amostras_doentes_treino = df[df['rotulo'] == nova_classe_idx].shape[0]\n",
    "print(f'O número de amostras na classe \"Doentes\" é: {numero_amostras_doentes_treino}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treino Saudáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número de amostras na classe \"Saudaveis\" é: 2163\n"
     ]
    }
   ],
   "source": [
    "#nome da nova classe\n",
    "nova_classe_saudaveis = 'Saudaveis'\n",
    "\n",
    "\n",
    "#verifica se classe ja esta no dataset\n",
    "if nova_classe_saudaveis not in treino.classes:\n",
    "    treino.classes.append(nova_classe_saudaveis)\n",
    "\n",
    "nova_classe_idx = len(treino.classes)\n",
    "\n",
    "\n",
    "novas_amostras = []\n",
    "\n",
    "# Itera pelas classes na lista e adiciona os elementos à lista criada anteriormente\n",
    "for caminho, rotulo in treino.imgs:\n",
    "    nome_classe = treino.classes[rotulo]\n",
    "    novo_rotulo = nova_classe_idx if nome_classe in saudaveis else rotulo\n",
    "    novas_amostras.append((caminho, novo_rotulo))\n",
    "\n",
    "# Atualiza as amostras no conjunto de treino\n",
    "treino.imgs = novas_amostras\n",
    "\n",
    "# Atualiza o DataFrame\n",
    "df['rotulo'] = [rotulo for (_, rotulo) in treino.imgs]\n",
    "\n",
    "\n",
    "numero_amostras_saudaveis_treino = df[df['rotulo'] == nova_classe_idx].shape[0]\n",
    "print(f'O número de amostras na classe \"Saudaveis\" é: {numero_amostras_saudaveis_treino}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para verificar se todos os dados foram unidos, podemos verificar quantos dados haviam em cada classe e quantos hão na nova classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número de amostras nas classes originais é: 4274\n",
      "O número de amostras saudaveis é: 2163\n",
      "O número de amostras doentes é: 2111\n",
      "O número de amostras somadas nas novas classes são: 4274\n"
     ]
    }
   ],
   "source": [
    "# Numero de amostras originais\n",
    "numero_amostras_classes_originais = df.shape[0]\n",
    "\n",
    "print(f'O número de amostras nas classes originais é: {numero_amostras_classes_originais}' )\n",
    "print(f'O número de amostras saudaveis é: {numero_amostras_saudaveis_treino}' )\n",
    "print(f'O número de amostras doentes é: {numero_amostras_doentes_treino}' )\n",
    "print(f'O número de amostras somadas nas novas classes são: {numero_amostras_doentes_treino+numero_amostras_saudaveis_treino}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos então aplicar as mesmas transformações no conjunto de testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste Doentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número de amostras na classe \"Doentes\" é: 55\n"
     ]
    }
   ],
   "source": [
    "#Para evitar acidentes, vou clonar o conjunto de treino e teste\n",
    "teste = dataset_teste\n",
    "\n",
    "#nome da nova classe\n",
    "nova_classe_doentes = 'Doentes'\n",
    "\n",
    "df = pd.DataFrame(teste.imgs, columns=['caminho', 'rotulo'])\n",
    "\n",
    "#verifica se classe ja esta no dataset\n",
    "if nova_classe_doentes not in teste.classes:\n",
    "    teste.classes.append(nova_classe_doentes)\n",
    "\n",
    "nova_classe_idx = len(teste.classes)\n",
    "\n",
    "\n",
    "novas_amostras = []\n",
    "\n",
    "# Itera pelas classes na lista e adiciona os elementos à lista criada anteriormente\n",
    "for caminho, rotulo in teste.imgs:\n",
    "    nome_classe = teste.classes[rotulo]\n",
    "    novo_rotulo = nova_classe_idx if nome_classe in doentes else rotulo\n",
    "    novas_amostras.append((caminho, novo_rotulo))\n",
    "\n",
    "# Atualiza as amostras no conjunto de treino\n",
    "teste.imgs = novas_amostras\n",
    "\n",
    "# Atualiza o DataFrame\n",
    "df['rotulo'] = [rotulo for (_, rotulo) in teste.imgs]\n",
    "\n",
    "\n",
    "numero_amostras_doentes_teste = df[df['rotulo'] == nova_classe_idx].shape[0]\n",
    "print(f'O número de amostras na classe \"Doentes\" é: {numero_amostras_doentes_teste}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste Saudáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número de amostras na classe \"Saudaveis\" é: 55\n"
     ]
    }
   ],
   "source": [
    "#nome da nova classe\n",
    "nova_classe_saudaveis = 'Saudaveis'\n",
    "\n",
    "\n",
    "#verifica se classe ja esta no dataset\n",
    "if nova_classe_saudaveis not in teste.classes:\n",
    "    teste.classes.append(nova_classe_saudaveis)\n",
    "\n",
    "nova_classe_idx = len(teste.classes)\n",
    "\n",
    "\n",
    "novas_amostras = []\n",
    "\n",
    "# Itera pelas classes na lista e adiciona os elementos à lista criada anteriormente\n",
    "for caminho, rotulo in teste.imgs:\n",
    "    nome_classe = teste.classes[rotulo]\n",
    "    novo_rotulo = nova_classe_idx if nome_classe in saudaveis else rotulo\n",
    "    novas_amostras.append((caminho, novo_rotulo))\n",
    "\n",
    "# Atualiza as amostras no conjunto de treino\n",
    "teste.imgs = novas_amostras\n",
    "\n",
    "# Atualiza o DataFrame\n",
    "df['rotulo'] = [rotulo for (_, rotulo) in teste.imgs]\n",
    "\n",
    "\n",
    "numero_amostras_saudaveis_teste = df[df['rotulo'] == nova_classe_idx].shape[0]\n",
    "print(f'O número de amostras na classe \"Saudaveis\" é: {numero_amostras_saudaveis_teste}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente verificando se todos os dados foram unidos corretamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número de amostras nas classes originais é: 110\n",
      "O número de amostras saudaveis é: 55\n",
      "O número de amostras doentes é: 55\n",
      "O número de amostras somadas nas novas classes são: 110\n"
     ]
    }
   ],
   "source": [
    "# Numero de amostras originais\n",
    "numero_amostras_classes_originais = df.shape[0]\n",
    "\n",
    "print(f'O número de amostras nas classes originais é: {numero_amostras_classes_originais}' )\n",
    "print(f'O número de amostras saudaveis é: {numero_amostras_saudaveis_teste}' )\n",
    "print(f'O número de amostras doentes é: {numero_amostras_doentes_teste}' )\n",
    "print(f'O número de amostras somadas nas novas classes são: {numero_amostras_doentes_teste+numero_amostras_saudaveis_teste}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando então como ficou o conjunto de treino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23 24]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Alstonia Scholaris diseased (P2a)',\n",
       " 'Alstonia Scholaris healthy (P2b)',\n",
       " 'Arjun diseased (P1a)',\n",
       " 'Arjun healthy (P1b)',\n",
       " 'Bael diseased (P4b)',\n",
       " 'Basil healthy (P8)',\n",
       " 'Chinar diseased (P11b)',\n",
       " 'Chinar healthy (P11a)',\n",
       " 'Gauva diseased (P3b)',\n",
       " 'Gauva healthy (P3a)',\n",
       " 'Jamun diseased (P5b)',\n",
       " 'Jamun healthy (P5a)',\n",
       " 'Jatropha diseased (P6b)',\n",
       " 'Jatropha healthy (P6a)',\n",
       " 'Lemon diseased (P10b)',\n",
       " 'Lemon healthy (P10a)',\n",
       " 'Mango diseased (P0b)',\n",
       " 'Mango healthy (P0a)',\n",
       " 'Pomegranate diseased (P9b)',\n",
       " 'Pomegranate healthy (P9a)',\n",
       " 'Pongamia Pinnata diseased (P7b)',\n",
       " 'Pongamia Pinnata healthy (P7a)',\n",
       " 'Doentes',\n",
       " 'Saudaveis']"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_no_dataframe = df['rotulo'].unique()\n",
    "print(classes_no_dataframe)\n",
    "treino.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ou seja, somente as classes 'Doentes' e 'Saudáveis' possuem dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:25px;\">Treinamento do modelo de Classificação</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O PyTorch fornece alguns modelos pré-treinados, como ResNet, VGG, entre outros. A vantagem de se utilizar um modelo pré-treinado são diversas, como: a menor capacidade computacional necessária para treinar um modelo; a menor quantidade de dados necessários; a atuação dos modelos pré-treinados como um tipo de regularização; entre outras. Nessa aplicação, usaremos o ResNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo escolhido\n",
    "modelo = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como esse modelo foi pre-treinado, podemos alterar sua última camada para que o modelo tenha o número correto de saídas. Ou seja,  podemos adaptar o modelo para trabalhar com nosso conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.fc = nn.Linear(modelo.fc.in_features, len(treino.classes)) #camada fully connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para definirmos o que queremos que o modelo faça, temos que definir sua função de perda. A função de perda quantifica quão bem o modelo está performando, sendo o objetivo do treinamento minimizar essa função de perda. Dependendo de qual a função de perda escolhida, o objetivo do modelo durante seu treino também muda. Como queremos que o modelo realize uma classificação com somente duas classes, podemos utilizar o HingeLoss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição da Hinge Loss\n",
    "criterio = nn.MultiMarginLoss(margin=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O parâmetro 'margin' do HingeLoss representa a relação entre a pontuação da classe que o modelo acha que é correta com a que ele acha que é incorreta. Caso essa relação seja menor que 1, sua perda não será mais nula. Com a relação já definida, é necessário implementar um otimizador, pois ele é o responsável por ajustar os pesos do modelo com base na função de perda. O otimizador escolhido foi o Adam, mas a escolha depende da realização de testes, e varia para cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definição do otimizador\n",
    "otimizador = optim.Adam(modelo.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:25px;\">Aplicação e Avaliação do Modelo</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os parâmetros já definidos, podemos então implementar o modelo. No pytorch, a implementação do modelo se resume a uma iteração do modelo sobre os dados de treino. O modelo classifica cada imagem do conjunto, verifica a perda e com base nisso recalcula os pesos, repetindo o processo pelo número de repetições definidas (epochs). Como meu computador não é muito moderno, decidi colocar uns checkpoints onde o código pode quebrar caso o tempo ultrapasse o limite definido e os valores do modelo estarão salvos. Também é possivel diminuir o número de epochs, o tamanho das imagens, a margin, entre outros. Entretanto, isso irá diminuir a acurácia do modelo ainda mais. Outra solução é o uso da GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n",
      "salvo\n",
      "Checkpoint salvo com sucesso: checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader_treino = DataLoader(treino, batch_size=64, shuffle=True) #iterador que escolhe 64 fotos aleatoriamente a cada epoch\n",
    "loader_teste = DataLoader(teste, batch_size=64, shuffle=True) #iterador que escolhe 64 fotos aleatoriamente a cada epoch\n",
    "\n",
    "repeticoes = 1\n",
    "save_interval = 1\n",
    "tempo_max = 7 * 60 * 60  # 7 horas\n",
    "start_time = time.time()\n",
    "tempo_limite = 0\n",
    "\n",
    "for epoch in range(repeticoes):\n",
    "    for imagens, rotulos in loader_treino:\n",
    "        if tempo_limite == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            otimizador.zero_grad()\n",
    "            saidas = modelo(imagens)\n",
    "            perda = criterio(saidas, rotulos)\n",
    "            perda.backward()\n",
    "            otimizador.step()\n",
    "\n",
    "            if epoch % save_interval == 0:\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': modelo.state_dict(),\n",
    "                    'optimizer_state_dict': otimizador.state_dict(),\n",
    "                }\n",
    "                torch.save(checkpoint, 'checkpoint.pth')\n",
    "                print('salvo')\n",
    "                if os.path.exists('checkpoint.pth'):\n",
    "                    print(f\"Checkpoint salvo com sucesso: {'checkpoint.pth'}\")\n",
    "                else:\n",
    "                    print(f\"Falha ao salvar o checkpoint: {'checkpoint.pth'}\")\n",
    "\n",
    "            if elapsed_time > tempo_max:\n",
    "                print(f\"Treinamento interrompido. Tempo máximo atingido ({tempo_max} segundos).\")\n",
    "\n",
    "                # Salvar último checkpoint antes de sair\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': modelo.state_dict(),\n",
    "                    'optimizer_state_dict': otimizador.state_dict(),\n",
    "                    # Adicione mais informações relevantes se necessário\n",
    "                }\n",
    "                torch.save(checkpoint, 'final_checkpoint.pth')\n",
    "\n",
    "                break\n",
    "        # Avaliação no conjunto de validação\n",
    "        # Adicione o código de avaliação aqui se necessário\n",
    "\n",
    "        modelo.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso o modelo teve seu treinamento interrompido antes dele terminar, temos que pegar seus parâmetros do checkpoint para poder avaliar seu rendimento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=24, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "checkpoint_path = 'checkpoint.pth'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "modelo.load_state_dict(checkpoint['model_state_dict'])\n",
    "modelo.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos então media a acurácia do modelo. Caso ele tenha tido seu treinamento interrompido, sua acurácia provavelmente não será ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.8\n"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imagens_val, rotulos_val in loader_teste:\n",
    "        # Passar os dados pelo modelo\n",
    "        saidas_val = modelo(imagens_val)\n",
    "\n",
    "        # Calcular as previsões\n",
    "        _, previsoes = torch.max(saidas_val, 1)\n",
    "\n",
    "        # Armazenar rótulos verdadeiros e previsões\n",
    "        true_labels.extend(rotulos_val.numpy())\n",
    "        predicted_labels.extend(previsoes.numpy())\n",
    "\n",
    "# Converter listas em arrays numpy para uso posterior\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Calcular e imprimir a acurácia\n",
    "acuracia = accuracy_score(true_labels, predicted_labels)\n",
    "print(f'Acurácia: {acuracia}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como é possivel observar, a acurácia obtida foi baixa, menor do que se você chutasse sempre que a planta é doente. Para melhorar isso, seria possivel aumentar o número de repetições, aumentar o tamanho das imagens, deixar o modelo terminar de treinar, no meu caso, entre outros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBS. Quando o codigo terminou de rodar 1 epoch, a acurácia foi de 0.8. Um valor bom e bem maior do que o coneseguido anteriormente,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
